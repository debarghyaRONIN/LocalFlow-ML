{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 6)\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target target_name  \n",
      "0       0      setosa  \n",
      "1       0      setosa  \n",
      "2       0      setosa  \n",
      "3       0      setosa  \n",
      "4       0      setosa  \n",
      "\n",
      "Summary Statistics:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)      target  \n",
      "count        150.000000  150.000000  \n",
      "mean           1.199333    1.000000  \n",
      "std            0.762238    0.819232  \n",
      "min            0.100000    0.000000  \n",
      "25%            0.300000    0.000000  \n",
      "50%            1.300000    1.000000  \n",
      "75%            1.800000    2.000000  \n",
      "max            2.500000    2.000000  \n",
      "\n",
      "Training set shape: (120, 4)\n",
      "Test set shape: (30, 4)\n",
      "\n",
      "Model Performance Metrics:\n",
      "accuracy: 0.9000\n",
      "precision: 0.9024\n",
      "recall: 0.9000\n",
      "f1: 0.8997\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.82      0.90      0.86        10\n",
      "   virginica       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.90      0.90      0.90        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "             feature  importance\n",
      "3   petal width (cm)    0.437185\n",
      "2  petal length (cm)    0.431466\n",
      "0  sepal length (cm)    0.116349\n",
      "1   sepal width (cm)    0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/07 20:07:54 INFO mlflow.tracking.fluent: Experiment with name 'iris-classifier-notebook' does not exist. Creating a new experiment.\n",
      "2025/04/07 20:08:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLflow Run ID: b2190af14ca24de6a5c9a167ae84b8f3\n",
      "\n",
      "Prediction Examples:\n",
      "Example 1:\n",
      "  Features: [5.1 3.5 1.4 0.2]\n",
      "  Predicted species: setosa\n",
      "  Probabilities: [1. 0. 0.]\n",
      "\n",
      "Example 2:\n",
      "  Features: [6.7 3.1 4.7 1.5]\n",
      "  Predicted species: versicolor\n",
      "  Probabilities: [0. 1. 0.]\n",
      "\n",
      "Example 3:\n",
      "  Features: [6.3 3.3 6.  2.5]\n",
      "  Predicted species: virginica\n",
      "  Probabilities: [0. 0. 1.]\n",
      "\n",
      "\n",
      "Exploration complete. All visualizations have been saved as PNG files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debar\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\debar\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# MLflow for tracking\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ## Loading the Iris Dataset\n",
    "# \n",
    "# The Iris dataset is a classic dataset for classification tasks. It includes 3 classes (species of iris flowers) with 50 samples each, and 4 features (sepal length, sepal width, petal length, petal width).\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "data = pd.DataFrame(X, columns=feature_names)\n",
    "data['target'] = y\n",
    "data['target_name'] = [target_names[t] for t in y]\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(data.head())\n",
    "\n",
    "# ## Exploratory Data Analysis\n",
    "# \n",
    "# Let's explore the dataset to understand its structure and characteristics.\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='target_name', data=data)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Pairplot to visualize relationships between features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(data, hue='target_name', vars=feature_names)\n",
    "plt.suptitle('Pairplot of Iris Features by Species', y=1.02)\n",
    "plt.savefig('pairplot.png')\n",
    "plt.close()\n",
    "\n",
    "# Box plots for each feature by species\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(feature_names):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.boxplot(x='target_name', y=feature, data=data)\n",
    "    plt.title(f'Box Plot of {feature} by Species')\n",
    "    plt.xlabel('Species')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.drop(['target_name'], axis=1).corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# ## Data Preparation\n",
    "# \n",
    "# Now, let's prepare the data for modeling by splitting it into training and test sets.\n",
    "\n",
    "# Split data into features and target\n",
    "X = data.drop(['target', 'target_name'], axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# ## Model Training\n",
    "# \n",
    "# Let's train a Random Forest model on the Iris dataset.\n",
    "\n",
    "# Define model parameters\n",
    "model_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Create and train the model\n",
    "model = RandomForestClassifier(**model_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ## Model Evaluation\n",
    "# \n",
    "# Now, let's evaluate our model's performance on the test set.\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "    'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "    'f1': f1_score(y_test, y_pred, average='weighted')\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# ## Feature Importance\n",
    "# \n",
    "# Let's analyze the importance of each feature in our model.\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# ## Tracking with MLflow\n",
    "# \n",
    "# Now, let's demonstrate how to track our model, parameters, and metrics with MLflow.\n",
    "\n",
    "try:\n",
    "    # Set MLflow tracking URI if needed\n",
    "    # mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    \n",
    "    # Set experiment\n",
    "    mlflow.set_experiment(\"iris-classifier-notebook\")\n",
    "    \n",
    "    # Log model, parameters, metrics with MLflow\n",
    "    with mlflow.start_run() as run:\n",
    "        # Log parameters\n",
    "        mlflow.log_params(model_params)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # Log feature importance\n",
    "        mlflow.log_dict(feature_importance.to_dict(), \"feature_importance.json\")\n",
    "        \n",
    "        print(f\"\\nMLflow Run ID: {run.info.run_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nMLflow tracking failed: {e}\")\n",
    "    print(\"Continuing without MLflow tracking...\")\n",
    "\n",
    "# ## Model Prediction Example\n",
    "# \n",
    "# Finally, let's demonstrate how to use the model to make predictions on new data.\n",
    "\n",
    "# Example new data point\n",
    "new_data = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Example of Iris setosa\n",
    "    [6.7, 3.1, 4.7, 1.5],  # Example of Iris versicolor\n",
    "    [6.3, 3.3, 6.0, 2.5]   # Example of Iris virginica\n",
    "])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_data)\n",
    "prediction_probabilities = model.predict_proba(new_data)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPrediction Examples:\")\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Features: {new_data[i]}\")\n",
    "    print(f\"  Predicted species: {target_names[pred]}\")\n",
    "    print(f\"  Probabilities: {prediction_probabilities[i]}\")\n",
    "    print(\"\")\n",
    "\n",
    "# ## Conclusion\n",
    "# \n",
    "# In this script, we explored the Iris dataset, trained a Random Forest classifier, evaluated its performance, and tracked the results with MLflow. This workflow mirrors the pipeline used in the LocalFlow-ML project, demonstrating how ML models can be developed, trained, and tracked in an MLOps environment.\n",
    "# \n",
    "# Key insights:\n",
    "# - The Iris dataset features are strong predictors for species classification\n",
    "# - The Random Forest model achieves high accuracy on this dataset\n",
    "# - Feature importance analysis shows which measurements are most predictive\n",
    "# - MLflow provides effective tracking and versioning of models and experiments\n",
    "\n",
    "print(\"\\nExploration complete. All visualizations have been saved as PNG files.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==2.21.3 (from mlflow)\n",
      "  Using cached mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (3.1.5)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (3.9.4)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (2.0.2)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Collecting pyarrow<20,>=4.0.0 (from mlflow)\n",
      "  Downloading pyarrow-19.0.1-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow) (1.13.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Downloading sqlalchemy-2.0.40-cp39-cp39-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.1)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached databricks_sdk-0.49.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (8.5.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (4.12.2)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (308)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Collecting itsdangerous>=2.2 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from matplotlib<4->mlflow) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from pandas<3->mlflow) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from pandas<3->mlflow) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.21.3->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.21.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2025.1.31)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (4.6.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\debar\\anaconda3\\envs\\main\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.2.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached mlflow-2.21.3-py3-none-any.whl (28.2 MB)\n",
      "Using cached mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\n",
      "Using cached alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading pyarrow-19.0.1-cp39-cp39-win_amd64.whl (25.5 MB)\n",
      "   ---------------------------------------- 0.0/25.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 3.1/25.5 MB 15.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.4/25.5 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.9/25.5 MB 23.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.1/25.5 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.5/25.5 MB 26.0 MB/s eta 0:00:00\n",
      "Downloading sqlalchemy-2.0.40-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 29.4 MB/s eta 0:00:00\n",
      "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached databricks_sdk-0.49.0-py3-none-any.whl (683 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Using cached Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: waitress, sqlparse, sqlalchemy, pyasn1, pyarrow, Mako, itsdangerous, graphql-core, deprecated, cachetools, blinker, uvicorn, starlette, rsa, pyasn1-modules, opentelemetry-api, graphql-relay, Flask, docker, alembic, opentelemetry-semantic-conventions, graphene, google-auth, fastapi, opentelemetry-sdk, databricks-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.1.0 Mako-1.3.9 alembic-1.15.2 blinker-1.9.0 cachetools-5.5.2 databricks-sdk-0.49.0 deprecated-1.2.18 docker-7.1.0 fastapi-0.115.12 google-auth-2.38.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 itsdangerous-2.2.0 mlflow-2.21.3 mlflow-skinny-2.21.3 opentelemetry-api-1.31.1 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9 sqlalchemy-2.0.40 sqlparse-0.5.3 starlette-0.46.1 uvicorn-0.34.0 waitress-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
